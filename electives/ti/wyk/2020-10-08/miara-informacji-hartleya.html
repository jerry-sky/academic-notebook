<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title></title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="/style.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Merriweather&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@500&display=swap" rel="stylesheet">
</head>
<body>
<h1 id="miara-informacji-hartleya">Miara Informacji Hartley’a</h1>
<p><em>(2020-10-08)</em></p>
<ul>
<li><a href="#1-addytywność-owej-miary">1. „Addytywność” owej miary</a></li>
<li><a href="#2-def-miara-ilości-informacji">2. DEF: <strong>Miara ilości informacji</strong></a>
<ul>
<li><a href="#21-uwaga">2.1. Uwaga</a></li>
<li><a href="#22-uwaga">2.2. Uwaga</a></li>
<li><a href="#23-własności-i">2.3. Własności <span class="math inline">\(I\)</span></a></li>
</ul></li>
<li><a href="#3-twierdzenie1">3. Twierdzenie#1</a>
<ul>
<li><a href="#31-d-d-twierdzenie1">3.1. D-d Twierdzenie#1</a>
<ul>
<li><a href="#311-eureka1">3.1.1. Eureka#1</a></li>
<li><a href="#312-eureka2">3.1.2. Eureka#2</a></li>
<li><a href="#313-kontynuacja-d-d-twierdzenie1">3.1.3. Kontynuacja D-d Twierdzenie#1</a></li>
<li><a href="#314-zatem">3.1.4. Zatem</a></li>
</ul></li>
</ul></li>
</ul>
<hr />
<p>Mamy zbiór <span class="math inline">\(X\)</span> <span class="math inline">\(N\)</span>-elementowy (elementy <span class="math inline">\(X\)</span> są jednakowo prawdopodobne)</p>
<p><span class="math inline">\(I_H(X) = \log_2N\)</span></p>
<h2 id="addytywność-owej-miary">1. „Addytywność” owej miary</h2>
<p><span class="math inline">\(X = \{x_1, x_2, \dots, x_{N\cdot M}\} ~~~ |X| = N\cdot M\)</span></p>
<p><span class="math inline">\(\widetilde{X} = \{X_1, X_2, \dots, X_M\}\)</span><br />
<span class="math inline">\(X_1 = \{x_1, \dots, x_N\}\)</span><br />
<span class="math inline">\(X_j = \{x_{(j-1)\cdot N +1}, \dots, x_{(j-1)\cdot N + N}\}\)</span><br />
<span class="math inline">\(\dotsc\)</span><br />
<span class="math inline">\(X_M\)</span></p>
<p><span class="math inline">\(I_H(X_j) = \log_2 N\)</span><br />
<span class="math inline">\(I_H(\widetilde{X}) = \log_2 M\)</span></p>
<p><span class="math inline">\(\bold{I_H(X) = \log_2(NM) = \log_2 N + \log_2 M = I_H(X_j) + I_H(\widetilde{X}).}\)</span></p>
<hr />
<p><span class="math inline">\(\widetilde{X} = \{X_1, X_2, \dots, X_N\}\)</span><br />
<span class="math inline">\(X = \dot{\bigcup}_{i=1}^N X_i ~~~ |X_i| = M_i\)</span> (w całym <span class="math inline">\(X\)</span> elementy są jednakowo prawdopodobne)</p>
<p><span class="math inline">\(I_H(X_j) = \log_2 M_j ~~~|~~~ I_H(X) = \log_2(\sum_{i=1}^N M_i)\)</span></p>
<p><span class="math inline">\(I_{?j}(\widetilde{X}) = I_H(X) - I_H(X_j) = \log_2\left( \frac{\sum_{i=1}^{N}}{M_j} \right) = \log_2 \frac{1}{p_j}\)</span> gdzie <span class="math inline">\(p_j\)</span> to p-o zdarzenia <span class="math inline">\(X_j\)</span>.</p>
<hr />
<h2 id="def-miara-ilości-informacji">2. DEF: <strong>Miara ilości informacji</strong></h2>
<p><span class="math inline">\(\bold{I: X \to \mathbb{R}}\)</span> gdzie <span class="math inline">\(X = \{x_1, \dots, x_N\}\)</span> jest dyskretną przestrzenią probabilistyczną</p>
<p><span class="math inline">\(P(x_i) = p_i ~~~~~ I(x_i) = -\log_2 p_i\)</span>.</p>
<h3 id="uwaga">2.1. Uwaga</h3>
<p>Ową definicję stosujemy też gdy <span class="math inline">\(X\)</span> jest (dyskretną) zmienną losową.</p>
<h3 id="uwaga-1">2.2. Uwaga</h3>
<p><span class="math inline">\(I: (0, 1] \to \mathbb{R}\)</span> też ma sens.</p>
<p><span class="math inline">\(I(x_i) ~~„=”~~ I(p_i) = -\log_2 p_i\)</span></p>
<h3 id="własności-i">2.3. Własności <span class="math inline">\(I\)</span></h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(I(1) = 0, I\left(\frac{1}{2}\right) = 1\)</span>, <span class="math inline">\(\lim_{i\to 0^+} I(p) = +\infty\)</span></li>
<li><span class="math inline">\(I(pq) = I(p) + I(q)\)</span><br />
mamy zdarzenie <span class="math inline">\(X\cap Y\)</span>, gdzie <span class="math inline">\(X,Y\)</span> niezależne, <span class="math inline">\(P(X) = p, P(Y) = q\)</span><br />
(coś jak <a href="#1-addytywność-owej-miary">„addytywność”</a> wcześniej)</li>
<li><span class="math inline">\(I\)</span> jest różniczkowalna</li>
</ol>
<hr />
<h2 id="twierdzenie1">3. Twierdzenie#1</h2>
<p>Jeśli <span class="math inline">\(I: (0,1] \to \mathbb{R}\)</span> jest różniczkowalną funkcją spełniającą <a href="#23-własności-i">2.3.2.</a> oraz <span class="math inline">\(I(\frac{1}{2}) = 1\)</span>,<br />
to <span class="math inline">\(I(p) = -\log_2p\)</span>.</p>
<h3 id="d-d-twierdzenie1">3.1. D-d Twierdzenie#1</h3>
<p><span class="math display">\[
I&#39;(p) = \lim_{\epsilon \to 0^-} \frac{I(p+\epsilon) - I(p) - I(p)}{\epsilon} =\\
\lim_{\epsilon \to 0^-} \frac{I(p+\epsilon p) - I(p)}{\epsilon p} = \text{(ponieważ 2.3.2.)}\\
\lim_{\epsilon \to 0^-} \frac{I(p) + I(1+\epsilon) - I(p)}{\epsilon p} =\\
\frac{1}{p}\lim_{\epsilon \to 0^-} \frac{I(1+\epsilon)}{\epsilon}
\]</span></p>
<h4 id="eureka1">3.1.1. Eureka#1</h4>
<p><span class="math inline">\(\lim\)</span> istnieje! #### 3.1.2. Eureka#2 <span class="math inline">\(\lim_{\epsilon \to 0^-} I(1+\epsilon) = 0\)</span>, czyli z ciągłości <span class="math inline">\(I(1) = 0\)</span>.</p>
<h4 id="kontynuacja-d-d-twierdzenie1">3.1.3. Kontynuacja D-d Twierdzenie#1</h4>
<p>Niech <span class="math inline">\(C = \lim_{\epsilon \to 0^-} \frac{I(1+\epsilon)}{\epsilon}\)</span></p>
<p><span class="math inline">\(I&#39;(p) = \frac{1}{p} \cdot C\)</span><br />
stąd <span class="math inline">\(I(p) = \int{ \frac{C}{p}\, dp} = C\cdot \ln p + D\)</span></p>
<p>Z <a href="#312-eureka2">Eureka#2</a> mamy <span class="math inline">\(I(1) = 0 = C\cdot \ln(1) + D = 0\)</span> czyli <span class="math inline">\(D = 0\)</span>.</p>
<p>Za to <span class="math inline">\(I(\frac{1}{2}) = 1 = C\cdot \ln(\frac{1}{2})\)</span> czyli <span class="math inline">\(C = -\frac{1}{\ln 2}\)</span>.</p>
<h4 id="zatem">3.1.4. Zatem</h4>
<p><span class="math inline">\(I(p) = \frac{- \ln p}{\ln 2} = \frac{- \ln 2 \log_2 p}{\ln 2} = -\log_2 p\)</span>.<br />
<span class="math inline">\(\blacksquare\)</span></p>
</body>
</html>
